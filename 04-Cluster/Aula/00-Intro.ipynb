{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução ao Clustering em Machine Learning\n",
    "\n",
    "Clustering é uma técnica fundamental em aprendizado de máquina não supervisionado que tem como objetivo descobrir estruturas intrínsecas em conjuntos de dados, agrupando pontos de dados similares em clusters distintos. Vamos explorar mais detalhadamente:\n",
    "\n",
    "## 1. Objetivo\n",
    "\n",
    "O principal objetivo do clustering é encontrar padrões e estruturas naturais em conjuntos de dados não rotulados. Ao agrupar os dados com base em similaridades, o clustering pode revelar informações valiosas sobre a natureza dos dados e as relações entre eles.\n",
    "\n",
    "## 2. Natureza não supervisionada\n",
    "\n",
    "Ao contrário do aprendizado supervisionado, onde os dados são rotulados, no clustering, os dados não têm rótulos prévios. Isso significa que não há uma resposta \"certa\" ou \"errada\" sobre como os dados devem ser agrupados. O algoritmo de clustering busca organizar os dados apenas com base em suas características intrínsecas.\n",
    "\n",
    "## 3. Medidas de Similaridade\n",
    "\n",
    "Os algoritmos de clustering geralmente usam medidas de similaridade, como distância euclidiana, para determinar a proximidade entre pontos de dados. Essas medidas são essenciais para calcular a similaridade entre os pontos e agrupá-los em clusters com base nessas distâncias.\n",
    "\n",
    "## 4. Algoritmos de Clustering\n",
    "\n",
    "Existem diversos algoritmos de clustering, cada um com suas próprias características e aplicações:\n",
    "\n",
    "- **`K-means`**: É um dos algoritmos mais populares. Ele agrupa os dados em K clusters, onde` K é especificado pelo usuário.` O algoritmo funciona iterativamente, movendo centróides de cluster para minimizar a soma das distâncias dos pontos de dados para os centróides.\n",
    "\n",
    "- **DBSCAN**: É um algoritmo baseado em densidade que agrupa pontos de dados em clusters de alta densidade, ignorando regiões com baixa densidade. Ele é eficaz para encontrar clusters de formas arbitrariamente complexas e é robusto a outliers.\n",
    "\n",
    "- **Hierarchical Clustering**: Este algoritmo cria uma hierarquia de clusters, onde os clusters podem ser visualizados em uma árvore dendrograma. Ele não requer o número de clusters como entrada, mas pode ser computacionalmente intensivo para grandes conjuntos de dados.\n",
    "\n",
    "## 5. Avaliação e Interpretação\n",
    "\n",
    "A avaliação dos resultados do clustering pode ser desafiadora, pois não há uma métrica definitiva para medir sua eficácia. A interpretação dos clusters é muitas vezes subjetiva e dependente do contexto do problema. Visualizações, como gráficos de dispersão ou dendrogramas, podem ser úteis para entender a estrutura dos clusters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Introdução ao agrupamento K-Means** <a class=\"anchor\" id=\"1\"></a>\n",
    "\n",
    "**Clustering K-Means** é o algoritmo de aprendizado não supervisionado mais popular. É usado quando temos dados não rotulados, que são dados sem categorias ou grupos definidos. O algoritmo segue uma forma fácil ou simples de classificar um determinado conjunto de dados através de um determinado número de clusters, fixos a priori. O algoritmo K-Means funciona iterativamente para atribuir cada ponto de dados a um dos K grupos com base nos recursos fornecidos. Os pontos de dados são agrupados com base na similaridade de recursos.\n",
    "\n",
    "O agrupamento K-Means pode ser representado da seguinte forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means\n",
    "\n",
    "![K-Means](https://miro.medium.com/max/2160/1*tWaaZX75oumVwBMcKN-eHA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algumas aplicações:**\n",
    "1. Segmentação de imagens\n",
    "\n",
    "2. Segmentação de clientes\n",
    "\n",
    "3. Agrupamento de espécies\n",
    "\n",
    "4. Detecção de anomalias\n",
    "\n",
    "5. Agrupamento de linguagens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. Intuição de agrupamento K-Means** <a class=\"anchor\" id=\"3\"></a>\n",
    "\n",
    "O agrupamento K-Means é usado para encontrar grupos intrínsecos dentro do conjunto de dados não rotulado e tirar inferências deles. É baseado em clustering baseado em centróide.\n",
    "\n",
    "\n",
    "**Centróide** - Um centróide é um ponto de dados no centro de um cluster. No clustering baseado em centróide, os clusters são representados por um centróide. É um algoritmo iterativo no qual a noção de similaridade é derivada da proximidade de um ponto de dados do centróide do cluster.\n",
    "O agrupamento K-Means funciona da seguinte maneira: -\n",
    "O algoritmo de agrupamento K-Means usa um procedimento iterativo para entregar um resultado final. O algoritmo requer o número de clusters K e o conjunto de dados como entrada. O conjunto de dados é uma coleção de recursos para cada ponto de dados. O algoritmo começa com estimativas iniciais para os K centróides. O algoritmo então itera entre duas etapas: -\n",
    "\n",
    "\n",
    "## **3.1 Etapa de atribuição de dados**\n",
    "\n",
    "\n",
    "Cada centróide define um dos clusters. Nesta etapa, cada ponto de dados é atribuído ao seu centróide mais próximo, que é baseado na distância euclidiana quadrada. Portanto, se Xi é a coleção de centróides no conjunto X, então cada ponto de dados é atribuído a um cluster com base na distância euclidiana mínima.\n",
    "\n",
    "\n",
    "\n",
    "## **3.2 Etapa de atualização do Centroid**\n",
    "\n",
    "\n",
    "Nesta etapa, os centróides são recalculados e atualizados. Isso é feito calculando a média de todos os pontos de dados atribuídos ao cluster desse centróide.\n",
    "\n",
    "\n",
    "O algoritmo então itera entre a etapa 1 e a etapa 2 até que um critério de parada seja atendido. Critérios de parada significam que nenhum ponto de dados altera os clusters, a soma das distâncias é minimizada ou algum número máximo de iterações é alcançado.\n",
    "É garantido que este algoritmo convirja para um resultado. O resultado pode ser um ótimo local, o que significa que avaliar mais de uma execução do algoritmo com centróides iniciais aleatórios pode fornecer um resultado melhor.\n",
    "\n",
    "A intuição K-Means pode ser representada com a ajuda do seguinte diagrama: -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![K-Means intuition](https://i.ytimg.com/vi/_aWzGGNrcic/hqdefault.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. Escolhendo o valor de K** <a class=\"anchor\" id=\"4\"></a>\n",
    "\n",
    "O algoritmo K-Means depende de encontrar o número de clusters e rótulos de dados para um valor predefinido de K. Para encontrar o número de clusters nos dados, precisamos executar o algoritmo de agrupamento K-Means para diferentes valores de K e compare os resultados. Portanto, o desempenho do algoritmo K-Means depende do valor de K. Devemos escolher o valor ideal de K que nos proporcione o melhor desempenho. Existem diferentes técnicas disponíveis para encontrar o valor ideal de K. A técnica mais comum é o **elbow method** que é descrito abaixo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **5. O elbow method** <a class=\"anchor\" id=\"5\"></a>\n",
    "\n",
    "O elbow method é usado para determinar o número ideal de clusters no cluster K-means. O elbow method traça o valor da função de custo produzido por diferentes valores de K."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Texto Alternativo](img\\elbow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que se K aumentar, a distorção média diminuirá. Então cada cluster terá menos instâncias constituintes e as instâncias estarão mais próximas de seus respectivos centróides. No entanto, as melhorias na distorção média diminuirão à medida que K aumenta. O valor de K no qual a melhoria na distorção diminui mais é chamado de cotovelo, no qual devemos parar de dividir os dados em outros grupos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vantagens do agrupamento K-Means:**\n",
    "\n",
    "1. **Simples** - É fácil de implementar\n",
    "\n",
    "2. **Alto desempenho** - A técnica de agrupamento K-Means é rápida e eficiente em termos de custo computacional\n",
    "\n",
    "4. **Fácil de interpretar** - K-Means retorna clusters que podem ser facilmente interpretados e visualizados\n",
    "\n",
    "5. **Adequado para grandes conjuntos de dados** Embora os algoritmos de cluster sejam relativamente lentos, o algoritmo k-means é comparativamente rápido, por isso é eficaz para grandes conjuntos de dados.\n",
    "\n",
    "\n",
    "**Desvantagens do agrupamento K-Means:**\n",
    "\n",
    "1. **Assume densidade esférica** - isso significa que o agrupamento k-means não funciona tão bem em situações em que os clusters têm naturalmente formas irregulares. Esta é uma suposição relativamente estrita.\n",
    "\n",
    "2. **Sensível à escala** - se uma das variáveis estiver em uma escala muito maior que as outras, essa variável terá um efeito desproporcional na distância calculada. Isso significa que geralmente precisamos redimensionar os dados antes de usar o clustering k-means.\n",
    "\n",
    "3. **Difícil de incorporar variáveis categóricas** - K-means destina-se a ser usado quando todos os seus recursos são numéricos. Existem maneiras de adaptar seus dados para que sejam adequados se você tiver alguns recursos categóricos, mas em geral a maioria dos seus recursos deve ser numérico.\n",
    "\n",
    "4. **Sensível a valores discrepantes** - K-Means não possui método de detecção de valores discrepantes. Os centróides podem ser arrastados por valores discrepantes ou os valores discrepantes podem obter seu próprio cluster em vez de serem ignorados.\n",
    "\n",
    "5. **Sensibilidade de inicialização** - O agrupamento K-means é sensível às condições iniciais usadas para inicializar o algoritmo, como a escolha da semente ou a ordem dos pontos de dados. Se não tivermos sorte na escolha dos pontos de partida, os clusters produzidos podem ser arbitrariamente ruins. Este é corrigido com uma variante conhecida como k-means++ (init padrão para sklearn)\n",
    "\n",
    "6. **É necessário escolher o número de clusters** - O clustering K-means requer a especificação antecipada do número de clusters que serão criados. Escolher o valor certo de 'k' é um problema desafiador de seleção de modelos.\n",
    "\n",
    "7. **Luta com dados dimensionais elevados** - O algoritmo depende da distância euclidiana, o que é muito ruim em dimensões altas. Se tivermos muitos recursos potenciais, devemos considerar a aplicação de algoritmos de seleção de recursos ou de redução de dimensionalidade aos dados antes de criar clusters.\n",
    "\n",
    "8. **O algoritmo é randomizado** - o que significa que podemos executá-lo no mesmo conjunto de dados várias vezes e obter respostas diferentes. Este é um grande problema para muitas aplicações.\n",
    "\n",
    "9. **k-means só pode separar clusters que são mais ou menos separáveis linearmente** - Se seus clusters forem baseados na distância até a origem, k-means não será capaz de identificá-los. Podemos consertar isso mudando para coordenadas polares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As maneiras de evitar o problema de sensibilidade de inicialização no algoritmo k-means:**\n",
    "\n",
    "1. **Repetir k-means** - o algoritmo é executado repetidamente. Os centróides são inicializados e os clusters são formados para resultar na menor distância intra-cluster e na maior distância entre cluster.\n",
    "\n",
    "2. **K-Means++** - uma técnica inteligente de inicialização de centróide. Apenas um centróide é inicializado aleatoriamente, e outros centróides são escolhidos de forma que estejam muito distantes do(s) centróide(s) inicial(is). Isso resulta em uma convergência mais rápida e menor possibilidade de o centróide ser mal inicializado. Inicialização padrão para sklearn.\n",
    "\n",
    "K significa++ fornece resultados comparativamente melhores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algumas das variações do algoritmo k-means:**\n",
    "\n",
    "1. **agrupamento de k-medianas** - usa a mediana em cada dimensão (em vez da média).\n",
    "\n",
    "2. **k-medoids (Particionamento em torno de Medoids)** - usa medoide em vez de média e minimiza a soma das distâncias para funções de distância arbitrárias.\n",
    "\n",
    "3. **Clustering Fuzzy C-Means** - uma versão suave do k-means, onde cada ponto de dados tem um grau difuso de pertencimento a cada cluster.\n",
    "\n",
    "4. **k-means++** - algoritmo k-means padrão com uma inicialização mais inteligente dos centróides (init padrão para sklearn)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
